{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Installing dependencies"
      ],
      "metadata": {
        "id": "R1BzOrJV3iDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install cohere\n",
        "!pip install qdrant-client\n",
        "!pip install PyPDF2\n",
        "\n"
      ],
      "metadata": {
        "id": "wjNA6XocYiyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "54-NXu4MY-fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reccomendation Model using cohere ai"
      ],
      "metadata": {
        "id": "n766LNTq3qJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use your own api key in variable cohere_api_key\n",
        "2. download and upload amazon dataset and set correct file path"
      ],
      "metadata": {
        "id": "Ef1nrsvV3uyU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZLZ8mIJYNpi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import tempfile\n",
        "import PyPDF2\n",
        "from typing import List\n",
        "from langchain.embeddings.cohere import CohereEmbeddings\n",
        "from langchain.llms import Cohere\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Qdrant\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Function to read text files\n",
        "def parse_txt(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        # Remove multiple newlines\n",
        "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
        "    return text\n",
        "\n",
        "# Function to read and parse PDF files\n",
        "def parse_pdf(file_path):\n",
        "    pdf = PyPDF2.PdfReader(file_path)\n",
        "    output = []\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        # Merge hyphenated words\n",
        "        text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
        "        # Fix newlines in the middle of sentences\n",
        "        text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", text.strip())\n",
        "        # Remove multiple newlines\n",
        "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
        "        output.append(text)\n",
        "    return output\n",
        "\n",
        "# Function to split text into smaller documents\n",
        "def text_to_docs(text: str) -> List[Document]:\n",
        "    \"\"\"Converts a string or list of strings to a list of Documents with metadata.\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        # Take a single string as one page\n",
        "        text = [text]\n",
        "    page_docs = [Document(page_content=page) for page in text]\n",
        "\n",
        "    # Add page numbers as metadata\n",
        "    for i, doc in enumerate(page_docs):\n",
        "        doc.metadata[\"page\"] = i + 1\n",
        "\n",
        "    # Split pages into chunks\n",
        "    doc_chunks = []\n",
        "\n",
        "    for doc in page_docs:\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=4000,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \"],\n",
        "            chunk_overlap=0,\n",
        "        )\n",
        "        chunks = text_splitter.split_text(doc.page_content)\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            doc_chunk = Document(\n",
        "                page_content=chunk, metadata={\"page\": doc.metadata[\"page\"], \"chunk\": i}\n",
        "            )\n",
        "            # Add sources as metadata\n",
        "            doc_chunk.metadata[\"source\"] = f\"{doc_chunk.metadata['page']}-{doc_chunk.metadata['chunk']}\"\n",
        "            doc_chunks.append(doc_chunk)\n",
        "    return doc_chunks\n",
        "\n",
        "# Cohere API Initiation\n",
        "cohere_api_key = ''  # Replace with your actual Cohere API key\n",
        "\n",
        "# Provide the path to the file here\n",
        "file_path = '/content/amazon.txt'  # Replace with the actual path to your PDF or TXT file\n",
        "\n",
        "# Determine the file type and parse accordingly\n",
        "if file_path.endswith(\".txt\"):\n",
        "    doc = parse_txt(file_path)\n",
        "else:\n",
        "    doc = parse_pdf(file_path)\n",
        "\n",
        "# Convert the parsed document to smaller documents\n",
        "pages = text_to_docs(doc)\n",
        "\n",
        "# Function to interact with the bot\n",
        "def chat_bot(pages, cohere_api_key):\n",
        "    # Create our own prompt template\n",
        "    prompt_template = \"\"\"Text: {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Answer the question based on the text provided. If the text doesn't contain the answer, reply that the answer is not available.\n",
        "    You are an ecommerce recommender chatbot analyze the question and provide top 5 products and their details like price category and description matching the user needs.\n",
        "    if user asks for cheap or economical sort by price of the product mentioned.\n",
        "    try to answer to only the specific question user asks , only reccommend top 5 for general reccomendation and searching queries\"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(\n",
        "        template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    if pages:\n",
        "        embeddings = CohereEmbeddings(\n",
        "            model=\"multilingual-22-12\", cohere_api_key=cohere_api_key\n",
        "        )\n",
        "        store = Qdrant.from_documents(\n",
        "            pages,\n",
        "            embeddings,\n",
        "            location=\":memory:\",\n",
        "            collection_name=\"my_documents\",\n",
        "            distance_func=\"Dot\",\n",
        "        )\n",
        "\n",
        "        while True:\n",
        "            question = input(\"Type your message here (or type 'exit' to quit): \")\n",
        "            if question.lower() == 'exit':\n",
        "                break\n",
        "\n",
        "            chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "            qa = RetrievalQA.from_chain_type(\n",
        "                llm=Cohere(model=\"command\", temperature=0, cohere_api_key=cohere_api_key),\n",
        "                chain_type=\"stuff\",\n",
        "                retriever=store.as_retriever(),\n",
        "                chain_type_kwargs=chain_type_kwargs,\n",
        "                return_source_documents=True,\n",
        "            )\n",
        "\n",
        "            answer = qa({\"query\": question})\n",
        "            result = answer[\"result\"].replace(\"\\n\", \"\").replace(\"Answer:\", \"\")\n",
        "            print(f\"Bot: {result}\")\n",
        "\n",
        "    else:\n",
        "        print(\"No file found. Upload a file to chat!\")\n",
        "\n",
        "# Start the chat bot\n",
        "chat_bot(pages, cohere_api_key)"
      ]
    }
  ]
}